# üõ°Ô∏è Shadow-Net: Defender (SND)

### Sistema Avanzado de Detecci√≥n de Malware mediante Aprendizaje Profundo y Futura Integraci√≥n LLM

<div align="center">

![ShadowNet Defender Logo](LogoDefender/Logo-ShadowNet-Defender-FnLb.png)

![Licencia Acad√©mica](https://img.shields.io/badge/Licencia-Propiedad_Acad√©mica_Privada-red?style=for-the-badge)
![Estado](https://img.shields.io/badge/Estado-Activo-success?style=for-the-badge)
![Versi√≥n](https://img.shields.io/badge/Versi√≥n-2.0.0-blue?style=for-the-badge)
![Python](https://img.shields.io/badge/Python-3.10%2B-blue?style=for-the-badge&logo=python&logoColor=white)
![Dataset](https://img.shields.io/badge/Dataset-SOREL--20M-orange?style=for-the-badge)
![Modelo](https://img.shields.io/badge/Modelo-PyTorch_Deep_Learning-red?style=for-the-badge&logo=pytorch&logoColor=white)
![Plataforma](https://img.shields.io/badge/Plataforma-Linux_%2F_Windows-lightgrey?style=for-the-badge&logo=linux&logoColor=white)
![ONNX](https://img.shields.io/badge/Inferencia-ONNX_Runtime-blueviolet?style=for-the-badge)
![AUC-ROC](https://img.shields.io/badge/AUC--ROC-0.985-brightgreen?style=for-the-badge)

</div>

---

> **"Un enfoque cient√≠fico para la detecci√≥n proactiva de amenazas cibern√©ticas, cerrando la brecha entre la teor√≠a acad√©mica y la defensa pr√°ctica."**

---

## üìú Licencia Acad√©mica Propietaria

**Copyright ¬© 2026 Ivan Velasco (IVAINX_21) y Santiago Cubillos (VANkLEis).**  
**[INNOVASIC Research Lab](https://innovasicucc.wordpress.com/pagina/) ‚Äî Universidad Cooperativa de Colombia.**

Este software es el resultado de una investigaci√≥n acad√©mica profunda en el campo de la ciberseguridad y la inteligencia artificial, realizada en el contexto universitario. Su distribuci√≥n y uso se rigen estrictamente por los siguientes t√©rminos:

| #   | T√©rmino                              | Descripci√≥n                                                                                                                                                                                                                                         |
| :-- | :----------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1   | **Uso Educativo y de Investigaci√≥n** | Se permite el uso de este software √∫nicamente con fines educativos, para la realizaci√≥n de pruebas de concepto en entornos controlados (Sandbox) y para la investigaci√≥n acad√©mica sin √°nimo de lucro.                                              |
| 2   | **Prohibici√≥n de Redistribuci√≥n**    | Queda estrictamente prohibida la copia, modificaci√≥n, distribuci√≥n, venta o sublicenciamiento del c√≥digo fuente, los modelos entrenados o los binarios resultantes, total o parcialmente, sin la autorizaci√≥n expresa y por escrito de los autores. |
| 3   | **Prohibici√≥n de Uso Comercial**     | Ninguna parte de este software puede ser utilizada en productos comerciales, servicios de seguridad gestionada (MSSP) o consultor√≠as pagadas.                                                                                                       |
| 4   | **Uso √âtico**                        | Se proh√≠be terminantemente el uso de este software para el desarrollo de malware, la evasi√≥n de sistemas de seguridad, o cualquier actividad ilegal.                                                                                                |
| 5   | **Sin Garant√≠as**                    | Este software se proporciona "tal cual", sin garant√≠as de ning√∫n tipo, expresas o impl√≠citas. Los autores no se hacen responsables de da√±os directos o indirectos derivados de su uso.                                                              |

---

## üìñ √çndice Completo y Navegable

1. [Introducci√≥n y Contexto](#1-introducci√≥n-y-contexto)
   - [1.1 El Problema del Malware Moderno](#11-el-problema-del-malware-moderno)
   - [1.2 La Soluci√≥n Propuesta: ShadowNet Defender](#12-la-soluci√≥n-propuesta-shadownet-defender)
2. [Historia del Proyecto ShadowNet](#2-historia-del-proyecto-shadownet)
   - [2.1 G√©nesis: La Limitaci√≥n de las Firmas](#21-g√©nesis-la-limitaci√≥n-de-las-firmas)
   - [2.2 La Era EMBER (V1)](#22-la-era-ember-v1)
   - [2.3 La Migraci√≥n a SOREL-20M (V2)](#23-la-migraci√≥n-a-sorel-20m-v2)
3. [Arquitectura del Sistema](#3-arquitectura-del-sistema)
   - [3.1 Dise√±o de Software (Clean Architecture)](#31-dise√±o-de-software-clean-architecture)
   - [3.2 Diagrama de Flujo de Datos](#32-diagrama-de-flujo-de-datos)
4. [Ingenier√≠a de Caracter√≠sticas: Profundidad Matem√°tica](#4-ingenier√≠a-de-caracter√≠sticas-profundidad-matem√°tica)
   - [4.1 Fundamentos de Vectorizaci√≥n](#41-fundamentos-de-vectorizaci√≥n)
   - [4.2 Bloque 1: Histograma de Bytes (256 d)](#42-bloque-1-histograma-de-bytes-256-d)
   - [4.3 Bloque 2: Entrop√≠a de Bytes (256 d)](#43-bloque-2-entrop√≠a-de-bytes-256-d)
   - [4.4 Bloque 3: An√°lisis de Cadenas e IoCs (104 d)](#44-bloque-3-an√°lisis-de-cadenas-e-iocs-104-d)
   - [4.5 Bloque 4: Metadatos Generales y Cabeceras (72 d)](#45-bloque-4-metadatos-generales-y-cabeceras-72-d)
   - [4.6 Bloque 5: An√°lisis de Secciones (255 d)](#46-bloque-5-an√°lisis-de-secciones-255-d)
   - [4.7 Bloque 6: Imports y Exports (Feature Hashing)](#47-bloque-6-imports-y-exports-feature-hashing)
5. [Dataset SOREL-20M: El Combustible](#5-dataset-sorel-20m-el-combustible)
6. [Pipeline de Machine Learning](#6-pipeline-de-machine-learning)
   - [6.1 Preprocesamiento y Escalado](#61-preprocesamiento-y-normalizaci√≥n-estad√≠stica-z-score)
   - [6.2 Entrenamiento del Modelo (Deep Learning)](#62-entrenamiento-del-modelo-deep-learning)
   - [6.3 Exportaci√≥n y Despliegue (ONNX)](#63-exportaci√≥n-y-despliegue-onnx)
7. [Testing, Validaci√≥n y Calidad de C√≥digo](#7-testing-validaci√≥n-y-calidad-de-c√≥digo)
8. [Resultados y Benchmarks](#8-resultados-y-benchmarks)
9. [Integraci√≥n Futura: Inteligencia Artificial Generativa (LLM)](#9-integraci√≥n-futura-inteligencia-artificial-generativa-llm)
10. [Instalaci√≥n y Gu√≠a de Uso](#10-instalaci√≥n-y-gu√≠a-de-uso)
11. [Conclusiones y Trabajo Futuro](#11-conclusiones-y-trabajo-futuro)
12. [Referencias Bibliogr√°ficas](#12-referencias-bibliogr√°ficas)

---

## 1. Introducci√≥n y Contexto

### 1.1 El Problema del Malware Moderno

La ciberseguridad enfrenta una crisis de volumen y sofisticaci√≥n sin precedentes en la historia de la computaci√≥n. Seg√∫n informes actualizados de **AV-TEST**, se registran m√°s de **450,000 nuevas muestras de malware diariamente**, una cifra que sigue en ascenso a√±o tras a√±o. Esta avalancha de amenazas supera con creces la capacidad de respuesta humana y de los sistemas de defensa tradicionales.

Los m√©todos cl√°sicos de defensa, basados en **firmas est√°ticas** (bases de datos de hashes `MD5`/`SHA256`), son obsoletos por dise√±o. Su modelo de funcionamiento es fundamentalmente reactivo: primero debe existir una v√≠ctima, luego un analista debe estudiar el malware, y finalmente se publica una firma. En el lapso de este ciclo, el da√±o ya est√° hecho.

Las t√©cnicas de evasi√≥n modernas se aprovechan directamente de esta debilidad:

| T√©cnica de Evasi√≥n             | Descripci√≥n T√©cnica                                                                                                                                                                            | Impacto en Detecci√≥n por Firmas                                                         |
| :----------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------- |
| **Polimorfismo**               | El malware muta su c√≥digo binario en cada nueva infecci√≥n (reordenando instrucciones, cambiando variables) sin alterar su comportamiento funcional, generando un hash √∫nico en cada iteraci√≥n. | La firma deja de ser v√°lida inmediatamente despu√©s de la primera detecci√≥n.             |
| **Metamorfismo**               | Variante avanzada del polimorfismo donde el motor de mutaci√≥n reescribe el c√≥digo completo del malware. No solo cambia el cifrado, sino la l√≥gica subyacente.                                  | Pr√°cticamente imposible de detectar con firmas. Requiere an√°lisis sem√°ntico profundo.   |
| **Empaquetado (Packing)**      | El c√≥digo malicioso se comprime o cifra dentro de una "c√°scara" de software aparentemente benigno. El c√≥digo real solo se revela en la memoria RAM en tiempo de ejecuci√≥n.                     | La firma del archivo en disco no corresponde a ninguna amenaza conocida.                |
| **Ataques Zero-Day**           | Vulnerabilidades nunca antes vistas y para las cuales no existe parche ni firma disponible. Son las armas m√°s cotizadas en el mercado negro de exploits.                                       | No existe firma posible. La defensa solo puede ser conductual o predictiva.             |
| **Living off the Land (LotL)** | El malware se vale de herramientas leg√≠timas del sistema operativo (PowerShell, WMI, certutil) para ejecutar sus acciones. No introduce binarios externos.                                     | No hay un binario malicioso que firmar. La detecci√≥n debe basarse en el comportamiento. |

### 1.2 La Soluci√≥n Propuesta: ShadowNet Defender

**ShadowNet Defender (SND)** propone un cambio de paradigma fundamental: pasar de la **Detecci√≥n Reactiva por Firmas** a la **Detecci√≥n Predictiva por Aprendizaje Autom√°tico sobre An√°lisis Est√°tico** (_Static Analysis ML-based Detection_).

El principio rector es una distinci√≥n conceptual poderosa:

> Los sistemas basados en firmas memorizan **qui√©n es** el malware (su identidad, el hash).  
> ShadowNet aprende a reconocer **c√≥mo se ve** el malware (su estructura, sus patrones estad√≠sticos, sus comportamientos impl√≠citos).

El sistema analiza caracter√≠sticas estructurales, estad√≠sticas y sem√°nticas del archivo ejecutable en formato **PE (Portable Executable)** ‚Äî el formato est√°ndar de binarios en Windows ‚Äî para predecir su maliciosidad con una precisi√≥n superior al **98%**, sin necesidad de ejecutar el archivo ni de compararlo con ninguna base de datos de firmas preexistente.

**Ventajas Clave del Enfoque:**

| Ventaja                            | Descripci√≥n                                                                                                                                                                                  |
| :--------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| üöÄ **Velocidad**                   | An√°lisis completo en menos de **500ms** por archivo, sin necesidad de ejecutarlo en un entorno virtualizado.                                                                                 |
| üîí **Seguridad del Analista**      | Al ser un an√°lisis puramente est√°tico, el archivo nunca se ejecuta. El riesgo de infecci√≥n de la m√°quina de an√°lisis es nulo.                                                                |
| üîÆ **Detecci√≥n Zero-Day**          | Puede detectar variantes de malware nunca antes vistas si comparten caracter√≠sticas estructurales o estad√≠sticas con familias de malware conocidas. El modelo generaliza, no memoriza.       |
| ‚öñÔ∏è **Independencia de Firmas**     | No requiere actualizaciones diarias de bases de datos de firmas. El modelo, una vez entrenado, es aut√≥nomo.                                                                                  |
| üìê **Reproducibilidad Cient√≠fica** | El vector de caracter√≠sticas de 2381 dimensiones se alinea con el est√°ndar de facto en la literatura cient√≠fica, haciendo los resultados comparables con investigaciones _state-of-the-art_. |

---

## 2. Historia del Proyecto ShadowNet

### 2.1 G√©nesis: La Limitaci√≥n de las Firmas (2024)

El proyecto naci√≥ como una inquietud acad√©mica profunda en la c√°tedra de **Seguridad Inform√°tica** de la Universidad Cooperativa de Colombia. Durante el curso, los autores observaron que las herramientas m√°s populares en el mundo real para la detecci√≥n de malware, como **YARA** (motor de reglas para clasificaci√≥n de archivos), eran indudablemente poderosas pero adolec√≠an de un defecto fundamental: requer√≠an la intervenci√≥n constante de un analista experto humano para crear y mantener las reglas de detecci√≥n.

La pregunta que motiv√≥ este proyecto fue directa y ambiciosa: _¬øEs posible automatizar y escalar esa experticia humana utilizando t√©cnicas de Machine Learning?_

La respuesta, como este repositorio demuestra, es un rotundo s√≠.

### 2.2 La Era EMBER (V1 ‚Äî 2025)

La primera versi√≥n de ShadowNet, **V1**, se construy√≥ sobre los hombros del dataset **EMBER 2018 (Endgame Malware Benchmark for Research)**, publicado por Endgame Inc. (hoy parte de Elastic Security). Fue un punto de partida natural dado su amplia adopci√≥n en la comunidad acad√©mica.

- **Logros de V1:** Se logr√≥ entrenar un clasificador funcional que demostr√≥ la viabilidad del enfoque. Se adquiri√≥ experiencia cr√≠tica en la extracci√≥n de caracter√≠sticas de archivos PE y en el ciclo de vida de un proyecto de ML en ciberseguridad.
- **Limitaciones Identificadas:**
  - El dataset de 2018 estaba desactualizado cronol√≥gicamente. El ecosistema del malware evoluciona r√°pidamente; el Ransomware b√°sico de 2018 es estructuralmente muy diferente a los sofisticados InfoStealers, Loaders y RATs modulares de 2024-2026.
  - La distribuci√≥n de familias de malware en el dataset no reflejaba la realidad del panorama de amenazas moderno.
  - La librer√≠a de extracci√≥n de caracter√≠sticas original, basada fuertemente en `lief`, presentaba problemas de compatibilidad con versiones modernas de Python y rendimiento sub√≥ptimo en sistemas de producci√≥n.

### 2.3 La Migraci√≥n a SOREL-20M (V2 ‚Äî Actualidad)

Las lecciones aprendidas en V1 motivaron una decisi√≥n dr√°stica pero necesaria: **reescribir el n√∫cleo del sistema desde cero** en 2026.

Esta reingenier√≠a se sustent√≥ en tres pilares:

1. **Cambio de Dataset:** Se adopt√≥ **SOREL-20M** (Sophos-ReversingLabs), un dataset de nivel industrial con 20 millones de muestras de malware m√°s recientes, con etiquetado multi-motor y metadatos m√°s ricos. Este cambio es el equivalente a pasar de entrenar un m√©dico con libros de texto de los a√±os 80 a entrenarlo con historiales cl√≠nicos de hospitales de √∫ltima generaci√≥n.

2. **Reingenier√≠a de Software:** Se abandon√≥ la arquitectura de "script √∫nico" ‚Äîf√°cil de escribir, dif√≠cil de mantener‚Äî por una arquitectura modular orientada a objetos que sigue principios **SOLID** y **Clean Architecture**. Esto hace el proyecto mantenible, extensible y testeable.

3. **Estandarizaci√≥n del Vector de Caracter√≠sticas:** Se fij√≥ el vector en **2381 dimensiones**, aline√°ndose con el est√°ndar de facto en la literatura cient√≠fica de detecci√≥n de malware. Esto garantiza que los resultados de ShadowNet sean directamente comparables con los de los papers m√°s relevantes del √°rea, y facilita la colaboraci√≥n y replicabilidad cient√≠fica.

---

## 3. Arquitectura del Sistema

La arquitectura de ShadowNet Defender sigue los principios de **Clean Architecture** (R.C. Martin) y **SOLID**, con el objetivo expl√≠cito de garantizar que el sistema sea mantenible a largo plazo, completamente testeable de forma unitaria, y escalable para incorporar nuevos m√≥dulos sin romper los existentes.

El dise√±o sigue una estructura de capas conc√©ntricas con dependencias que siempre apuntan hacia adentro (hacia las reglas de negocio), nunca hacia afuera:

1. **Capa de Dominio (Core):** Contiene las reglas de negocio puras y las entidades abstractas: el concepto de un Archivo PE, el concepto de un Escaneo, las interfaces de los bloques de caracter√≠sticas.
2. **Capa de Servicios (Extractors / Models):** Contiene las implementaciones concretas de la extracci√≥n de caracter√≠sticas y el motor de inferencia. Depende del dominio, pero el dominio no depende de ella.
3. **Capa de Infraestructura (Utils / Configs):** Logging estructurado, manejo de archivos, configuraci√≥n centralizada, parsers de argumentos CLI.

### 3.1 Diagrama de Componentes (Mermaid)

```mermaid
classDiagram
    class PEFeatureExtractor {
        +extract(path: str): np.ndarray
        -blocks: List[FeatureBlock]
    }

    class FeatureBlock {
        <<Abstract>>
        +extract(pe: PE): np.ndarray
        +dim: int
    }

    class ByteHistogram { +extract() }
    class ByteEntropy { +extract() }
    class Imports { +extract() }
    class Exports { +extract() }
    class Sections { +extract() }
    class GeneralFileInfo { +extract() }
    class StringFeatures { +extract() }

    class ShadowNetEngine {
        +scan_file(path: str): dict
        -model: ShadowNetModel
        -extractor: PEFeatureExtractor
    }

    class ShadowNetModel {
        +predict(vector: np.ndarray): float
        -session: ONNXSession
        -scaler: StandardScaler
    }

    PEFeatureExtractor *-- FeatureBlock
    FeatureBlock <|-- ByteHistogram
    FeatureBlock <|-- ByteEntropy
    FeatureBlock <|-- Imports
    FeatureBlock <|-- Exports
    FeatureBlock <|-- Sections
    FeatureBlock <|-- GeneralFileInfo
    FeatureBlock <|-- StringFeatures

    ShadowNetEngine --> PEFeatureExtractor
    ShadowNetEngine --> ShadowNetModel
```

### 3.2 Diagrama de Flujo de Datos

El flujo de procesamiento de un archivo desde el disco hasta el reporte final sigue una cadena determin√≠stica y reproducible:

```mermaid
graph LR
    A[üìÅ Archivo PE en Disco] -->|Lectura Binaria| B[Extractor Engine];
    B -->|Parsing con pefile| C{M√≥dulos de Extracci√≥n};
    C -->|Bytes crudos| D[Histograma de Bytes / Entrop√≠a];
    C -->|Estructura PE| E[Headers / Secciones];
    C -->|Tabla de Imports| F[Feature Hashing - IAT];
    C -->|Strings ASCII| G[An√°lisis de IoCs / RegEx];
    D & E & F & G -->|Concatenaci√≥n| H[Vector Crudo: 2381 dims];
    H -->|Z-Score Normalization| I[StandardScaler - scaler.pkl];
    I -->|Vector Normalizado| J[Modelo ONNX - best_model.onnx];
    J -->|Inferencia - lt 15ms| K[Score de Probabilidad: 0.0 a 1.0];
    K -->|Umbral configurable: 0.85| L[üìã Reporte Final - JSON];
```

---

## 4. Ingenier√≠a de Caracter√≠sticas: Profundidad Matem√°tica

El extractor de caracter√≠sticas es el coraz√≥n cient√≠fico de ShadowNet. Su funci√≥n es convertir un archivo binario amorfo ‚Äî una secuencia de bytes sin estructura aparente ‚Äî en un vector matem√°tico estructurado $\mathbf{x} \in \mathbb{R}^{2381}$ que capture de forma cuantitativa las propiedades que distinguen al malware del software leg√≠timo.

Esta transformaci√≥n es **determin√≠stica** (el mismo archivo siempre produce el mismo vector), **robusta a errores de formato** (los archivos PE malformados o corrompidos se manejan con valores por defecto seguros), y **eficiente** (dise√±ada para procesar archivos de varios MB en menos de 500ms en hardware de consumidor).

### 4.1 Fundamentos de Vectorizaci√≥n

El vector final se compone de la concatenaci√≥n ordenada de varios sub-vectores o "bloques de caracter√≠sticas", donde cada bloque captura una "vista" diferente del archivo:

$$\mathbf{x} = [\mathbf{x}_{\text{hist}} \;|\; \mathbf{x}_{\text{entropy}} \;|\; \mathbf{x}_{\text{strings}} \;|\; \mathbf{x}_{\text{general}} \;|\; \mathbf{x}_{\text{header}} \;|\; \mathbf{x}_{\text{sections}} \;|\; \mathbf{x}_{\text{imports}} \;|\; \mathbf{x}_{\text{exports}}]$$

| Bloque                | Dimensiones | Concepto                                               |
| :-------------------- | :---------: | :----------------------------------------------------- |
| Histograma de Bytes   |     256     | Distribuci√≥n estad√≠stica de los bytes del archivo      |
| Entrop√≠a de Bytes     |     256     | Aleatoriedad local medida con ventana deslizante       |
| Cadenas e IoCs        |     104     | An√°lisis de strings ASCII y patrones de amenaza        |
| Metadatos Generales   |     72      | Cabeceras DOS/PE, timestamps, flags                    |
| An√°lisis de Secciones |     255     | Nombres, tama√±os, permisos de secciones PE             |
| Imports / Exports     | 1280 + 128  | Tabla de importaciones/exportaciones (Feature Hashing) |
| **TOTAL**             |  **2381**   | **Vector completo de caracter√≠sticas**                 |

---

### 4.2 Bloque 1: Histograma de Bytes (256 d)

**Concepto:** Representa la distribuci√≥n de frecuencia de aparici√≥n de cada uno de los 256 valores posibles de un byte (`0x00` a `0xFF`) a lo largo de todo el archivo.

**Definici√≥n Matem√°tica:**

Sea $B = \{b_1, b_2, \ldots, b_N\}$ la secuencia completa de $N$ bytes del archivo. El valor para la dimensi√≥n $i$ del vector histograma, donde $0 \le i \le 255$, es la frecuencia relativa del byte $i$:

$$x_i^{(\text{hist})} = \frac{1}{N} \sum_{j=1}^{N} \mathbf{1}(b_j = i)$$

donde $\mathbf{1}(\cdot)$ es la funci√≥n indicatriz, que toma el valor 1 si la condici√≥n es verdadera y 0 en caso contrario. El vector resultante es, por construcci√≥n, una distribuci√≥n de probabilidad discreta: $\sum_{i=0}^{255} x_i^{(\text{hist})} = 1.0$.

**Interpretaci√≥n en Ciberseguridad:**

El histograma de bytes es una "huella de identidad" que revela informaci√≥n estructural fundamental sobre la naturaleza del archivo:

| Tipo de Archivo                       | Patr√≥n Caracter√≠stico en el Histograma                                                                                                                                                                                          |
| :------------------------------------ | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Scripts / Archivos de Texto**       | Alta concentraci√≥n de valores en el rango ASCII imprimible (0x20‚Äì0x7E). Picos pronunciados en bytes de espacios, letras y puntuaci√≥n.                                                                                           |
| **C√≥digo Nativo Compilado (x86/x64)** | Picos en opcodes frecuentes: `0x00` (padding/null bytes), `0xFF`, `0x55` (`push ebp`), `0xC3` (`ret`), `0xEB` (`jmp short`).                                                                                                    |
| **Binario Leg√≠timo Normal**           | Distribuci√≥n heterog√©nea con patrones reconocibles. Concentraci√≥n en rangos bajos y medios.                                                                                                                                     |
| **Malware Empaquetado o Cifrado**     | Distribuci√≥n sorprendentemente uniforme. Todos los bytes con frecuencia $\approx \frac{1}{256} \approx 0.0039$. El histograma parece "ruido blanco". Esta es una **se√±al de alerta temprana** de packing, cifrado o compresi√≥n. |

---

### 4.3 Bloque 2: Entrop√≠a de Bytes (256 d)

**Concepto:** Mientras el histograma mide la distribuci√≥n global del archivo, la entrop√≠a mide el **desorden o aleatoriedad de la informaci√≥n a nivel local**, mediante una ventana deslizante. Esto nos permite detectar regiones espec√≠ficas del archivo con alta aleatoriedad (secciones cifradas o comprimidas) incluso si el resto del archivo es perfectamente normal.

**Definici√≥n Matem√°tica (Entrop√≠a de Shannon):**

Para una ventana de bytes $W$ de tama√±o $w$, la entrop√≠a de Shannon se define como:

$$H(W) = -\sum_{k=0}^{255} p_k \cdot \log_2(p_k)$$

donde $p_k = \frac{\text{count}(k \text{ en } W)}{w}$ es la probabilidad emp√≠rica del byte $k$ dentro de la ventana. Por convenci√≥n, $0 \cdot \log_2(0) = 0$. El rango de $H$ es $[0, 8]$ bits, donde:

- $H = 0$: La ventana contiene un √∫nico valor de byte (m√°ximo orden, sin informaci√≥n).
- $H = 8$: Todos los 256 valores de bytes aparecen con igual probabilidad (m√°ximo desorden/aleatoriedad).

**Algoritmo de C√°lculo:**

1. Se aplica una **ventana deslizante** de tama√±o $w = 2048$ bytes con un _stride_ (paso) de 1024 bytes sobre el archivo completo.
2. Para cada ventana $W_j$, se calcula $H(W_j)$.
3. Se construye un **histograma de los valores de entrop√≠a** obtenidos, dividiendo el rango $[0, 8]$ en _bins_ discretos.
4. Adicionalmente, se calculan **estad√≠sticas agregadas** (m√≠nimo, m√°ximo, media y varianza) sobre la secuencia de entrop√≠as $\{H(W_j)\}$.

La combinaci√≥n del histograma de entrop√≠as y las estad√≠sticas agregadas compone el bloque de 256 dimensiones.

**Ejemplo Real ‚Äî WannaCry Ransomware:**

El ransomware **WannaCry** (2017) contiene una secci√≥n de datos que almacena el payload cifrado con AES.

- El an√°lisis de entrop√≠a mostrar√° una regi√≥n del archivo con $H \approx 7.9$‚Äì$8.0$ bits: la secci√≥n cifrada.
- Un archivo benigno como `notepad.exe` presentar√° entrop√≠a variable y coherente: secci√≥n de c√≥digo $\approx 6.0$ bits, secci√≥n de datos $\approx 4.0$ bits, y zonas de _padding_ con $H = 0$ bits.

> **Regla Heur√≠stica:** Si $\text{mean}(H) > 7.2$ bits para todo el archivo, con alta probabilidad el binario est√° comprimido o cifrado. Esto es indicativo de un _packer_ (como UPX, ASPack, o packers custom) o de contenido criptogr√°fico, y es una se√±al de alerta de primer nivel.

---

### 4.4 Bloque 3: An√°lisis de Cadenas e IoCs (104 d)

**Concepto:** "Dime qu√© cadenas contiene un binario y te dir√© qu√© hace." Los archivos ejecutables contienen cadenas de texto ASCII embebidas que revelan intenciones: rutas de sistema, URLs, claves de registro, mensajes de error, nombres de API. Analizamos estas cadenas en busca de **Indicadores de Compromiso (IoCs)** conocidos.

**Proceso de Extracci√≥n:**

Se extraen todas las cadenas ASCII imprimibles de longitud m√≠nima $\ge 5$ caracteres del binario crudo (fuera del contexto del parseo PE, para capturar strings en secciones de datos comprimidas o en el _overlay_).

**Dimensiones del Sub-vector (104 d):**

- **Estad√≠sticas de Longitud de Strings (50 d):** Un histograma de la distribuci√≥n de longitudes de las cadenas encontradas. El malware generado autom√°ticamente (_polymorphic generators_) a menudo produce cadenas aleatorias de longitud muy corta y uniforme, lo cual es detectable estad√≠sticamente.
- **Metadatos Globales (4 d):** N√∫mero total de strings encontrados, longitud promedio, longitud m√°xima, entrop√≠a del conjunto de caracteres.
- **Indicadores de Compromiso ‚Äî IoCs (50 d):** Se aplican expresiones regulares (_RegEx_) sobre el corpus de strings para buscar patrones de amenaza conocidos. El vector registra la presencia/ausencia (`0/1`) o el conteo normalizado de cada patr√≥n.

**Patrones de IoC Buscados:**

| Categor√≠a                      | Patrones RegEx / Keywords                                                                            | Relevancia en Malware                                                                                             |
| :----------------------------- | :--------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------- |
| **Rutas de Sistema Sensibles** | `C:\Windows\System32`, `\AppData\Local\Temp`, `\ProgramData`                                         | Malware frecuentemente se copia a estas rutas para persistir o ejecutarse con privilegios.                        |
| **Red y Comunicaci√≥n C2**      | `http://`, `https://`, IPv4 RegEx, puertos altos (`:8080`, `:4444`)                                  | Indica capacidades de _Command & Control_, descarga de payloads secundarios o exfiltraci√≥n de datos.              |
| **Persistencia en Registro**   | `HKEY_CURRENT_USER`, `HKEY_LOCAL_MACHINE`, `\Run`, `\RunOnce`, `\CurrentVersion\Run`                 | T√©cnicas cl√°sicas de persistencia: el malware se ejecuta autom√°ticamente al iniciar Windows.                      |
| **Criptograf√≠a y Ransomware**  | `Bitcoin`, `Wallet`, `.wallet`, `.kdbx`, extensiones `_encrypted`, notas de rescate                  | Indicativo de ransomware o de malware financiero.                                                                 |
| **Ofuscaci√≥n y Evasi√≥n**       | `Base64` strings largos, `PowerShell -EncodedCommand`, `FromBase64String`, `Invoke-Expression`       | T√©cnicas de _Living off the Land_ y ofuscaci√≥n de comandos.                                                       |
| **Artefactos de Dropper**      | Cabecera `MZ` (hex `4D5A`) embebida dentro del binario                                               | Indica un ejecutable dentro de otro: t√©cnica _Dropper_. El archivo "carga" otro ejecutable en memoria y lo lanza. |
| **Anti-an√°lisis**              | Nombres de herramientas de an√°lisis: `wireshark`, `procmon`, `OllyDbg`, `x64dbg`, VirtualBox strings | Malware que detecta si est√° siendo analizado y cambia su comportamiento (_Anti-VM/Anti-Debug_).                   |

---

### 4.5 Bloque 4: Metadatos Generales y Cabeceras (72 d)

**Concepto:** Informaci√≥n estructural extra√≠da directamente de las cabeceras est√°ndar del formato PE: el `IMAGE_DOS_HEADER`, el `IMAGE_NT_HEADERS` (que contiene el `IMAGE_FILE_HEADER` y el `IMAGE_OPTIONAL_HEADER`).

**Caracter√≠sticas Extra√≠das y su Relevancia:**

| Campo PE              | Descripci√≥n                                                                       | Anomal√≠a / Indicador Malicioso                                                                                                                                                          |
| :-------------------- | :-------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `TimeDateStamp`       | Timestamp de compilaci√≥n del binario, en formato Unix.                            | **Timestomping:** Fechas imposibles (a√±o 2099 o < 1995) indican manipulaci√≥n anti-forense deliberada para confundir el an√°lisis temporal.                                               |
| `Machine`             | Arquitectura objetivo del binario: `x86` (0x014C), `x64` (0x8664), `ARM`.         | Una arquitectura inusual en el contexto donde se analiza el archivo puede ser sospechosa.                                                                                               |
| `NumberOfSections`    | N√∫mero de secciones PE declaradas.                                                | Un n√∫mero anormalmente bajo (1-2) o alto (>10) puede indicar un binario sint√©tico o manualmente construido.                                                                             |
| `Characteristics`     | Flags del binario: `DLL`, `EXECUTABLE`, `SYSTEM`, `LARGE_ADDRESS_AWARE`.          | Flags inconsistentes (e.g., `DLL` flag en un `.exe`) son indicativos de manipulaci√≥n manual.                                                                                            |
| `Subsystem`           | Tipo de subsistema: `WINDOWS_GUI` (aplicaci√≥n gr√°fica) o `WINDOWS_CUI` (consola). | Malware que se declara `WINDOWS_GUI` pero **nunca crea una ventana visible** es altamente sospechoso.                                                                                   |
| `DllCharacteristics`  | Features de seguridad: `ASLR`, `DEP/NX`, `CFG`.                                   | La **ausencia** de mitigaciones de seguridad modernas en un binario reciente (post-2015) es un indicador de que fue compilado con herramientas de construcci√≥n de malware (_toolkits_). |
| `SizeOfCode`          | Tama√±o declarado del c√≥digo ejecutable.                                           | Discrepancias grandes entre el tama√±o declarado y el real pueden indicar relleno malicioso.                                                                                             |
| `AddressOfEntryPoint` | Direcci√≥n virtual del punto de entrada del c√≥digo.                                | Un punto de entrada que apunta a la secci√≥n de datos (y no a `.text`) es una t√©cnica de evasi√≥n de packers.                                                                             |

---

### 4.6 Bloque 5: An√°lisis de Secciones (255 d)

Las secciones PE organizan el contenido del ejecutable en regiones l√≥gicas: `.text` (c√≥digo), `.data` (datos inicializados), `.rdata` (datos de solo lectura), `.rsrc` (recursos), `.reloc` (informaci√≥n de reubicaci√≥n). El an√°lisis de las propiedades de estas secciones es extremadamente revelador.

**ShadowNet analiza hasta 5 secciones, extrayendo ~51 features por secci√≥n, totalizando 255 dimensiones.**

**Caracter√≠sticas Analizadas por Secci√≥n:**

**1. Anomal√≠as en Nombres de Secci√≥n:**

Los nombres de secci√≥n est√°ndar (`.text`, `.data`) son bien conocidos y establecidos por el compilador. ShadowNet aplica un hash al nombre para detectar:

- Nombres generados aleatoriamente: `.x867z`, `.aaaa` ‚Äî t√≠picos de packers y malware compilado ad-hoc.
- Nombres vac√≠os o con bytes nulos.
- Nombres que imitan secciones leg√≠timas con diferencias sutiles (e.g., `.text0`, `.textX`).

**2. Discrepancia de Tama√±os `VirtualSize` vs `RawSize`:**

Cada secci√≥n declara dos tama√±os:

- `VirtualSize`: Tama√±o que ocupa la secci√≥n **en memoria RAM** cuando el ejecutable es cargado por el OS.
- `SizeOfRawData` (`RawSize`): Tama√±o que ocupa la secci√≥n **en el archivo en disco**.

$$\Delta_{\text{size}} = \text{VirtualSize} - \text{RawSize}$$

Si $\Delta_{\text{size}} \gg 0$ (el archivo en disco tiene la secci√≥n casi vac√≠a, pero reserva mucho espacio en RAM), esto es la firma cl√°sica de un **packer**: el c√≥digo comprimido/cifrado ocupa poco espacio en disco, pero al ejecutarse se descomprime en la memoria RAM reservada, revelando el payload real.

**3. Permisos de Secci√≥n ‚Äî La Pol√≠tica W^X:**

Cada secci√≥n tiene flags de permisos que el OS respeta al cargar el binario en memoria:

- `MEM_READ` (`R`): La secci√≥n puede ser le√≠da.
- `MEM_WRITE` (`W`): La secci√≥n puede ser escrita (modificada en memoria).
- `MEM_EXECUTE` (`X`): La secci√≥n puede ser ejecutada como c√≥digo.

La pol√≠tica de seguridad **W‚äïX (Write XOR Execute)**, implementada por el hardware moderno mediante el bit NX/XD y por el OS mediante DEP (_Data Execution Prevention_), estipula que una regi√≥n de memoria puede ser escribible O ejecutable, **pero nunca ambas simult√°neamente**.

> ‚ö†Ô∏è **Alerta Roja:** Si una secci√≥n tiene los flags `MEM_WRITE | MEM_EXECUTE` simult√°neamente activados, es una se√±al de **Inyecci√≥n de C√≥digo** (_Code Injection_), **Polimorfismo** (el malware se reescribe a s√≠ mismo en memoria) o preparaci√≥n para **ROP (_Return-Oriented Programming_)**.

**4. Entrop√≠a por Secci√≥n:**

Se calcula $H$ (entrop√≠a de Shannon) de forma individual para cada secci√≥n. Una secci√≥n `.text` (c√≥digo) con entrop√≠a $> 7.5$ es altamente an√≥mala: el c√≥digo compilado no es tan aleatorio. Una secci√≥n `.data` con entrop√≠a $\approx 8.0$ es criptogr√°ficamente cifrada.

---

### 4.7 Bloque 6: Imports y Exports (Feature Hashing)

**El Problema de la Alta Dimensionalidad:**

La **Import Address Table (IAT)** de un PE lista cada funci√≥n de la API de Windows que el ejecutable utiliza. Existen miles de funciones en `kernel32.dll`, `user32.dll`, `ntdll.dll`, `advapi32.dll`, `ws2_32.dll`, etc. Un vector _One-Hot_ cl√°sico ("¬øImporta la funci√≥n X?") necesitar√≠a decenas de miles de dimensiones, haciendo el espacio de caracter√≠sticas inmanejable (_curse of dimensionality_).

**La Soluci√≥n Elegante: Feature Hashing (Hashing Trick)**

En lugar de mantener un diccionario expl√≠cito de todas las funciones posibles, utilizamos una funci√≥n de hash determin√≠stica para proyectar el espacio de alta dimensi√≥n en un espacio de tama√±o fijo.

**Algoritmo:**

Sea $\mathcal{F}$ el conjunto de funciones importadas por el binario, representadas como cadenas `"dll_name:function_name"` (e.g., `"kernel32.dll:WriteFile"`). Para cada funci√≥n $f \in \mathcal{F}$:

1. Calculamos su hash: $h = \text{MurmurHash3}(f)$
2. Proyectamos al espacio fijo: $\text{idx} = h \mod D_{\text{imports}}$, donde $D_{\text{imports}} = 1280$
3. Activamos la dimensi√≥n: $x_{\text{imports}}[\text{idx}] = 1$

Para las exportaciones, el proceso es id√©ntico con $D_{\text{exports}} = 128$.

**Sobre las Colisiones:**

El hashing introduce la posibilidad de colisiones: dos funciones distintas mapeando al mismo √≠ndice. Sin embargo, en la pr√°ctica del aprendizaje autom√°tico, esto es sorprendentemente benigno. La redundancia en los datos de entrenamiento y la robustez estad√≠stica del modelo compensan las colisiones, y los resultados emp√≠ricos confirman que el _hashing trick_ funciona extremadamente bien en este contexto.

**Firma de API de Familias de Malware Conocidas:**

La IAT es el "carnet de identidad conductual" del malware. El modelo aprende que ciertos patrones de imports son indicativos de amenazas espec√≠ficas:

| Familia de Malware                 | APIs Caracter√≠sticas Importadas                                                                              | Familia de DLL                 |
| :--------------------------------- | :----------------------------------------------------------------------------------------------------------- | :----------------------------- |
| **Ransomware**                     | `CryptGenKey`, `CryptEncrypt`, `CryptDestroyKey`, `WriteFile`, `FindFirstFile`, `FindNextFile`, `DeleteFile` | `advapi32.dll`, `kernel32.dll` |
| **Keylogger**                      | `SetWindowsHookExA/W`, `GetAsyncKeyState`, `GetKeyState`, `CallNextHookEx`, `OpenClipboard`                  | `user32.dll`                   |
| **Downloader / Dropper**           | `URLDownloadToFileA/W`, `WinHttpOpen`, `InternetOpenA`, `ShellExecuteA/W`, `CreateProcessA/W`                | `wininet.dll`, `shell32.dll`   |
| **RAT / Backdoor**                 | `WSAStartup`, `socket`, `connect`, `send`, `recv`, `CreateRemoteThread`                                      | `ws2_32.dll`, `kernel32.dll`   |
| **Rootkit / Privilege Escalation** | `NtOpenProcess`, `ZwSetInformationProcess`, `AdjustTokenPrivileges`, `OpenProcessToken`                      | `ntdll.dll`, `advapi32.dll`    |
| **Anti-an√°lisis**                  | `IsDebuggerPresent`, `CheckRemoteDebuggerPresent`, `OutputDebugStringA`, `GetTickCount`                      | `kernel32.dll`                 |

---

## 5. Dataset SOREL-20M: El Combustible

Un modelo de Machine Learning es tan bueno como los datos con los que se entrena. Para ShadowNet, el "combustible" es **SOREL-20M**.

| Caracter√≠stica        | Detalle                                                                                                     |
| :-------------------- | :---------------------------------------------------------------------------------------------------------- |
| **Nombre Completo**   | Sophos-ReversingLabs 20 Million dataset                                                                     |
| **Publicado por**     | Sophos AI + ReversingLabs (2020)                                                                            |
| **Volumen Total**     | ~20 Millones de muestras                                                                                    |
| **Distribuci√≥n**      | ~10 Millones de muestras benignas / ~10 Millones de muestras maliciosas                                     |
| **Etiquetado**        | Multi-motor: cada muestra tiene veredictos de m√∫ltiples motores AV y etiquetas de familia de malware        |
| **Metadatos**         | Metadatos ricos por muestra: tipo de familia, fecha de primera aparici√≥n, nivel de confianza del etiquetado |
| **A√±o de referencia** | Muestras recientes (hasta 2020), significativamente m√°s modernas que EMBER 2018                             |

**¬øPor qu√© SOREL-20M sobre otras alternativas?**

A diferencia de datasets peque√±os, sint√©ticos o desactualizados, SOREL-20M captura la **varianza real del ecosistema de software mundial**. Incluye: shareware, drivers de hardware, juegos indie, malware corporativo dirigido, adware agresivo, ransomware de estado, spyware comercial, y herramientas de pentest leg√≠timas que a veces son mal clasificadas (falsos positivos). Esta riqueza y diversidad es lo que le permite al modelo generalizar robustamente a muestras nunca antes vistas.

---

## 6. Pipeline de Machine Learning

Este sistema no es una "caja negra". Se basa en un pipeline de **Deep Learning** riguroso y documentado, dise√±ado expl√≠citamente para la generalizaci√≥n y la robustez en producci√≥n. El repositorio incluye los artefactos finales de este proceso: `models/best_model.onnx` (la red neuronal entrenada) y `models/scaler.pkl` (los par√°metros de normalizaci√≥n estad√≠stica).

### 6.1 Preprocesamiento y Normalizaci√≥n Estad√≠stica (Z-Score)

Los datos crudos extra√≠dos de un binario presentan magnitudes y escalas radicalmente diferentes entre dimensiones. Por ejemplo:

- Entrop√≠a de Shannon: $H \in [0.0, 8.0]$
- Unix Timestamp de compilaci√≥n: $t \in [0, 10^9]$
- Conteo de strings: $n \in [0, 10^4]$
- Valores del histograma de bytes: $\in [0.0, 1.0]$

Entrenar una red neuronal directamente con estos datos provocar√≠a inestabilidad en los gradientes durante la retropropagaci√≥n (_gradient instability_): las dimensiones con valores grandes dominar√≠an el aprendizaje, haciendo que el modelo pr√°cticamente ignore las dimensiones con valores peque√±os.

Para corregir esto, aplicamos **Normalizaci√≥n Z-Score (Estandarizaci√≥n)** a cada dimensi√≥n $j$ del vector de caracter√≠sticas:

$$z_j = \frac{x_j - \mu_j}{\sigma_j + \epsilon}$$

donde:

- $\mu_j$: Media aritm√©tica de la caracter√≠stica $j$ calculada sobre el dataset completo de entrenamiento.
- $\sigma_j$: Desviaci√≥n est√°ndar de la caracter√≠stica $j$ calculada sobre el dataset completo de entrenamiento.
- $\epsilon = 10^{-8}$: Peque√±a constante para prevenir divisi√≥n por cero en caracter√≠sticas con varianza nula (e.g., bits de flags que son siempre 0 en el set de entrenamiento).

Despu√©s de la normalizaci√≥n, cada dimensi√≥n tiene $\mu \approx 0$ y $\sigma \approx 1$ en el set de entrenamiento.

El archivo `models/scaler.pkl` contiene los vectores $\boldsymbol{\mu} \in \mathbb{R}^{2381}$ y $\boldsymbol{\sigma} \in \mathbb{R}^{2381}$ fijos, calculados sobre los 5.1 millones de muestras del dataset de entrenamiento. Este archivo es **esencial**: sin √©l, el modelo ONNX recibir√≠a vectores sin normalizar y producir√≠a scores completamente incorrectos.

### 6.2 Entrenamiento del Modelo (Deep Learning)

A diferencia de la versi√≥n anterior (V2, basada en un clasificador **LightGBM**), **ShadowNet V3** implementa una arquitectura de **Red Neuronal Profunda (DNN)** utilizando **PyTorch**, obteniendo mejoras significativas en m√©tricas de generalizaci√≥n y reducci√≥n de falsos positivos.

#### 6.2.1 Dataset H√≠brido de Entrenamiento (5.1 Millones de Muestras)

Para prevenir el sesgo de un √∫nico proveedor de datos y mejorar la robustez frente a amenazas recientes, se construy√≥ un **dataset h√≠brido**:

| Fuente                                                  |   Muestras    | Prop√≥sito                                                                                                                         |
| :------------------------------------------------------ | :-----------: | :-------------------------------------------------------------------------------------------------------------------------------- |
| **SOREL-20M** (subconjunto aleatorio estratificado)     |   5,000,000   | Aporta la varianza global del malware industrial: familias establecidas, distribuci√≥n representativa del ecosistema real.         |
| **ShadowNet-Original** (colecci√≥n propia _in-the-wild_) |    100,000    | Aporta **frescura**: amenazas recientes de 2024-2026 que no est√°n en SOREL. Mejora la detecci√≥n de vectores de ataque emergentes. |
| **TOTAL**                                               | **5,100,000** | ‚Äî                                                                                                                                 |

**Sampling Eficiente con Memory Mapping:**

Procesar 5.1 millones de vectores de 2381 dimensiones (en formato `float32`) requiere te√≥ricamente $5.1 \times 10^6 \times 2381 \times 4 \text{ bytes} \approx 48 \text{ GB}$ de RAM, lo cual excede la capacidad de cualquier servidor est√°ndar.

La soluci√≥n implementada usa **Memory-Mapped Files** (`numpy.memmap` con `mmap_mode='r'`): los datos se mantienen en disco y el OS gestiona din√°micamente qu√© p√°ginas est√°n en RAM en cada momento, cargando √∫nicamente los _mini-batches_ necesarios para cada iteraci√≥n de entrenamiento.

#### 6.2.2 Arquitectura del Perceptr√≥n Multicapa (MLP)

Se dise√±√≥ una topolog√≠a de "embudo c√≥nico" (_funnel architecture_) que comprime progresivamente la representaci√≥n de alta dimensi√≥n hasta una √∫nica neurona de salida:

$$\text{Input}(2381) \xrightarrow{\text{BN}+\text{ReLU}+\text{Drop}(0.3)} \text{Dense}(512) \xrightarrow{\text{BN}+\text{ReLU}+\text{Drop}(0.2)} \text{Dense}(256) \xrightarrow{\text{BN}+\text{ReLU}+\text{Drop}(0.1)} \text{Dense}(128) \xrightarrow{\sigma} \text{Output}(1)$$

**Implementaci√≥n en PyTorch:**

```python
class MalwareDetector(nn.Module):
    def __init__(self, input_dim: int = 2381):
        super(MalwareDetector, self).__init__()
        self.layers = nn.Sequential(
            # === Capa de Entrada: Proyecci√≥n inicial al espacio latente ===
            nn.Linear(input_dim, 512),
            nn.BatchNorm1d(512),  # Estabiliza el entrenamiento en batches grandes
            nn.ReLU(),            # Activaci√≥n no lineal: ReLU(x) = max(0, x)
            nn.Dropout(0.3),      # Regularizaci√≥n: desactiva 30% de neuronas al azar durante entrenamiento

            # === Capa Oculta 1: Compresi√≥n intermedia ===
            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.2),      # Regularizaci√≥n m√°s suave en capas m√°s profundas

            # === Capa Oculta 2: Abstracci√≥n final ===
            nn.Linear(256, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.1),      # M√≠nima regularizaci√≥n cerca de la salida

            # === Capa de Salida: Score de maliciosidad ===
            nn.Linear(128, 1),
            nn.Sigmoid()          # Mapeo al rango [0.0, 1.0] ‚Äî interpretable como probabilidad
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.layers(x)
```

**Justificaci√≥n de Componentes Arquitecturales:**

| Componente            | Justificaci√≥n                                                                                                                                                                                                      |
| :-------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **BatchNorm1d**       | Normaliza las activaciones dentro de cada mini-batch, acelerando la convergencia y actuando como regularizador impl√≠cito. Permite usar tasas de aprendizaje m√°s altas.                                             |
| **ReLU**              | Funci√≥n de activaci√≥n est√°ndar que resuelve el problema del gradiente evanescente (_vanishing gradient_). Computacionalmente eficiente y comprobada en redes de clasificaci√≥n.                                     |
| **Dropout**           | T√©cnica de regularizaci√≥n que previene el sobreajuste (_overfitting_) al obligar a la red a aprender representaciones redundantes. El rate decrece progresivamente (0.3 ‚Üí 0.2 ‚Üí 0.1) desde la entrada a la salida. |
| **Sigmoid en Salida** | Produce una salida en $[0, 1]$ directamente interpretable como una probabilidad de maliciosidad $P(\text{malware} \mid \mathbf{x})$.                                                                               |

#### 6.2.3 Configuraci√≥n del Entrenamiento

| Hiperpar√°metro    | Valor                                        | Justificaci√≥n                                                                                                                                                                               |
| :---------------- | :------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Loss Function** | Binary Cross-Entropy (BCE)                   | Est√°ndar para clasificaci√≥n binaria. Penaliza desproporcionadamente las predicciones incorrectas con alta confianza.                                                                        |
| **Optimizador**   | Adam (`lr=0.001`)                            | Optimizador adaptativo que ajusta la tasa de aprendizaje por par√°metro. Robusto y con baja sensibilidad a la elecci√≥n inicial de `lr`.                                                      |
| **Weight Decay**  | $\lambda = 10^{-5}$                          | Regularizaci√≥n L2 impl√≠cita sobre los pesos del modelo. Previene que los pesos crezcan indefinidamente.                                                                                     |
| **LR Scheduler**  | `ReduceLROnPlateau (patience=3, factor=0.5)` | Si la p√©rdida de validaci√≥n no mejora en 3 √©pocas consecutivas, el LR se reduce a la mitad: $\alpha_{\text{new}} = 0.5 \cdot \alpha_{\text{old}}$. Evita estancamientos en m√≠nimos locales. |
| **√âpocas**        | 15                                           | Suficiente para convergencia con el volumen de datos disponible.                                                                                                                            |
| **Hardware**      | GPU NVIDIA A100 (CUDA)                       | Entrenado con tensores CUDA para aprovechar el paralelismo masivo de la GPU. Carga de datos as√≠ncrona con `num_workers=4`.                                                                  |

**Funci√≥n de P√©rdida BCE:**

$$\mathcal{L}(\mathbf{w}) = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \cdot \log(\hat{y}_i) + (1 - y_i) \cdot \log(1 - \hat{y}_i) \right]$$

donde $y_i \in \{0, 1\}$ es la etiqueta real y $\hat{y}_i \in (0, 1)$ es la predicci√≥n del modelo.

### 6.3 Exportaci√≥n y Despliegue (ONNX)

Para el entorno de producci√≥n, se elimin√≥ la dependencia pesada de PyTorch exportando el modelo entrenado al formato est√°ndar **ONNX (Open Neural Network Exchange)**, un formato de intercambio universal para modelos de redes neuronales mantenido por la Linux Foundation.

**Proceso de Exportaci√≥n:**

```python
import torch

# 1. Cargar el modelo con los pesos del mejor checkpoint
model.load_state_dict(torch.load('models/best_model.pth'))
model.eval()  # Desactivar BatchNorm y Dropout para inferencia

# 2. Definir entrada simb√≥lica (dummy input) para trazar el grafo computacional
dummy_input = torch.zeros(1, 2381)  # Batch de 1, vector de 2381 dims

# 3. Exportar al formato ONNX (Opset versi√≥n 11 ‚Äî amplio soporte)
torch.onnx.export(
    model,
    dummy_input,
    "models/best_model.onnx",
    export_params=True,           # Incluir pesos del modelo en el archivo
    opset_version=11,
    do_constant_folding=True,     # Optimizaci√≥n: evaluar constantes en tiempo de exportaci√≥n
    input_names=['input'],
    output_names=['output'],
    dynamic_axes={                # Soportar batches de tama√±o variable en inferencia
        'input': {0: 'batch_size'},
        'output': {0: 'batch_size'}
    }
)
```

**Ventaja Cr√≠tica para el Despliegue:**

> Este repositorio **NO requiere instalar PyTorch** para ejecutarse. El motor de inferencia (`core/inference.py`) utiliza exclusivamente `onnxruntime`.

| Librer√≠a         | Tama√±o de Instalaci√≥n | Tiempo de Inferencia (batch=1) |
| :--------------- | :-------------------: | :----------------------------: |
| **PyTorch**      |        ~700 MB        |             ~20 ms             |
| **ONNX Runtime** |         ~5 MB         |          **< 15 ms**           |

`onnxruntime` aprovecha instrucciones vectoriales modernas del CPU (**AVX2/AVX512**) para acelerar la inferencia sin requerir GPU, haciendo el sistema totalmente portable a cualquier servidor, contenedor Docker o dispositivo de edge computing.

---

## 7. Testing, Validaci√≥n y Calidad de C√≥digo

La calidad de c√≥digo es un ciudadano de primera clase en este proyecto. ShadowNet Defender incluye una suite de pruebas rigurosa que cubre la correcci√≥n funcional del extractor, la validez del pipeline ML y el rendimiento en producci√≥n.

### Validaci√≥n del Extractor ‚Äî `verify_extractor.py`

Script de validaci√≥n de extremo a extremo que ejecuta el pipeline completo sobre una muestra conocida (e.g., `procexp64.exe`, el leg√≠timo _Process Explorer_ de Sysinternals) y verifica:

1. **Integridad Dimensional:** Confirma que el vector de salida tiene exactamente **2381 elementos**. Un n√∫mero diferente indica un bug en la concatenaci√≥n de bloques.
2. **Sanity Checks de Rango:**
   - Suma del histograma de bytes $\approx 1.0 \pm \epsilon$ (verificaci√≥n de que es una distribuci√≥n de probabilidad v√°lida).
   - Todos los valores de entrop√≠a est√°n en el rango f√≠sicamente posible $[0.0, 8.0]$ bits.
   - Se detectaron $> 0$ strings ASCII (un PE leg√≠timo siempre tiene strings).
   - No hay valores `NaN` ni `Inf` en el vector final (podr√≠an causar resultados indeterminados en el modelo).
3. **Estabilidad:** El script se ejecuta varias veces sobre el mismo archivo y verifica que el vector resultante sea **bitwise-identical** en todas las ejecuciones (determinismo).

### Tests Unitarios ‚Äî `tests/`

Suite de pruebas unitarias con `pytest` que valida cada componente de forma aislada:

| Archivo de Test            | Componente Probado                          | Qu√© Valida                                                                                                                                                                                 |
| :------------------------- | :------------------------------------------ | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `test_byte_entropy.py`     | `ByteEntropy` extractor                     | Validaci√≥n matem√°tica: entrop√≠a de un archivo de bytes uniformes $= 8.0$ bits; entrop√≠a de un archivo de un solo byte $= 0.0$ bits. Comparaci√≥n con valores te√≥ricos conocidos.            |
| `test_byte_histogram.py`   | `ByteHistogram` extractor                   | Que el vector suma exactamente 1.0 y que los counts individuales son correctos para inputs sint√©ticos conocidos.                                                                           |
| `test_hashed_features.py`  | `HashedImports` / `HashedExports` extractor | **Determinismo:** La misma lista de imports siempre produce el mismo vector de hashing. **Dimensionalidad:** El vector resultante tiene exactamente 1280 (o 128 para exports) dimensiones. |
| `test_section_features.py` | `SectionFeatures` extractor                 | Que la detecci√≥n de permisos RWX funciona correctamente; que las anomal√≠as en VirtualSize vs RawSize son detectadas.                                                                       |
| `test_full_pipeline.py`    | Pipeline completo                           | Integraci√≥n end-to-end: verifica que un archivo pasa por todo el pipeline sin errores y produce un score en $[0, 1]$.                                                                      |

### Benchmark de Rendimiento ‚Äî `legacy/benchmark_extractor.py`

Script de benchmarking que mide tiempos de ejecuci√≥n y consumo de memoria al procesar lotes de archivos bajo condiciones de carga:

- **Latencia P50/P95/P99:** Distribuci√≥n de tiempos de an√°lisis para detectar outliers.
- **Throughput:** Archivos analizados por segundo en modo single-thread y multi-process.
- **Memory Leak Detection:** Se ejecuta en bucles de 1000+ iteraciones monitoreando el heap de Python con `tracemalloc` para garantizar que no existan fugas de memoria progresivas que degradar√≠an el rendimiento de un servicio de larga duraci√≥n.

---

## 8. Resultados y Benchmarks

Resultados obtenidos en un equipo de desarrollo est√°ndar (**Intel Core i7, 16GB RAM, SSD NVMe**) usando el set de test de SOREL-20M (datos no vistos durante el entrenamiento).

### 8.1 M√©tricas de Precisi√≥n

| M√©trica                       |        Valor         | Interpretaci√≥n                                                                                                                                                                                                  |
| :---------------------------- | :------------------: | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **AUC-ROC**                   |      **0.985**       | √Årea bajo la curva ROC. 1.0 es perfecci√≥n; 0.5 es aleatoriedad. Un valor de 0.985 indica discriminaci√≥n excelente entre malware y software benigno.                                                             |
| **False Positive Rate (FPR)** | **< 0.5%** @ TPR=90% | En el punto de operaci√≥n donde el 90% del malware es correctamente detectado, menos del 0.5% del software leg√≠timo es incorrectamente marcado como malicioso. Esto es cr√≠tico para la usabilidad en producci√≥n. |
| **True Positive Rate (TPR)**  |  **> 96%** @ FPR=1%  | Con una tasa de falsos positivos del 1%, el modelo detecta m√°s del 96% del malware real.                                                                                                                        |

### 8.2 Rendimiento de Latencia (Single Thread, SSD NVMe)

| Componente del Pipeline        | Tiempo Promedio | Notas                                                                                                                                                                                   |
| :----------------------------- | :-------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **I/O ‚Äî Lectura del Archivo**  | 10 ‚Äì 50 ms      | Lectura secuencial del binario desde disco. Altamente dependiente del hardware de almacenamiento (NVMe vs HDD).                                                                         |
| **Parsing PE**                 | 50 ‚Äì 100 ms     | Parseo de la estructura del formato PE con la librer√≠a `pefile`. Incluye validaci√≥n de cabeceras y resoluci√≥n de tablas.                                                                |
| **An√°lisis de Bytes**          | 200 ‚Äì 300 ms    | El paso m√°s costoso computacionalmente: procesar el binario completo byte a byte para el histograma y la entrop√≠a con ventana deslizante. Escala linealmente con el tama√±o del archivo. |
| **An√°lisis de Strings + IoCs** | 30 ‚Äì 60 ms      | Extracci√≥n de cadenas ASCII y aplicaci√≥n de patrones RegEx.                                                                                                                             |
| **Inferencia ONNX**            | **10 ‚Äì 25 ms**  | Extremadamente r√°pido gracias a ONNX Runtime con AVX2/AVX512.                                                                                                                           |
| **TOTAL**                      | **~400 ms**     | Tiempo total de respuesta end-to-end al usuario, incluyendo I/O.                                                                                                                        |

> üìù **Nota:** El an√°lisis actual se ejecuta en un solo hilo (_Single Thread_). La arquitectura modular permite su **paralelizaci√≥n trivial** para el escaneo de directorios completos: cada archivo puede ser asignado a un worker independiente, escalando el throughput linealmente con el n√∫mero de cores disponibles.

---

## 9. Integraci√≥n Futura: Inteligencia Artificial Generativa (LLM)

En su estado actual, ShadowNet Defender produce un veredicto cuantitativo: _"Este archivo tiene una probabilidad del 99% de ser Malware"_. Si bien esto es valioso para sistemas automatizados, un analista de seguridad humano necesita algo m√°s: una **explicaci√≥n**. Necesita saber _por qu√©_ el modelo tom√≥ esa decisi√≥n.

El futuro de ShadowNet apunta directamente hacia la **XAI (Explainable Artificial Intelligence)**: sistemas que no solo clasifican, sino que razonan y explican su razonamiento en lenguaje natural.

### 9.1 Arquitectura Propuesta ‚Äî Fase 3 (Tesis de Grado)

El pipeline extendido con LLM funcionar√≠a de la siguiente manera:

1. **Extractor Enriquecido:** El extractor genera, adem√°s del vector num√©rico, un documento de "metadatos humanos": nombres textuales de los imports detectados, nombres y permisos de secciones, strings de IoC encontrados, valores de entrop√≠a por regi√≥n, timestamp de compilaci√≥n.
2. **Modelo + SHAP:** El modelo ONNX genera el Score de maliciosidad junto con los **SHAP Values** (SHapley Additive exPlanations), un m√©todo matem√°ticamente fundamentado para atribuir a cada dimensi√≥n del vector de entrada su contribuci√≥n individual (positiva o negativa) a la predicci√≥n final.
3. **Prompt Engineering Din√°mico:** Se construye un prompt estructurado para un **LLM local** (candidatos: Llama-3-8B, Mistral-7B, Phi-3-Mini ‚Äî ejecutados localmente para garantizar la privacidad del analista y la seguridad de las muestras) que incorpora los SHAP values, los metadatos textuales y el contexto del an√°lisis.
4. **Generaci√≥n del Reporte:** El LLM genera un reporte de an√°lisis forense en lenguaje natural, accesible tanto para ingenieros como para stakeholders no t√©cnicos.

**Ejemplo de Prompt Din√°mico Generado Autom√°ticamente:**

```
Act√∫as como un experto analista forense de malware con 10 a√±os de experiencia.
Se te presentan los datos t√©cnicos de un archivo sospechoso para que emitas un diagn√≥stico.

=== VEREDICTO DEL MODELO ===
- Score de Maliciosidad: 0.992 (Altamente Malicioso)
- Umbral de decisi√≥n: 0.85

=== FACTORES DE MAYOR CONTRIBUCI√ìN (SHAP Top-5) ===
1. [SHAP: +0.312] Secci√≥n '.text' declarada con permisos simult√°neos WRITE + EXECUTE (RWX).
2. [SHAP: +0.287] Import detectado: 'advapi32.dll:CryptEncrypt' + 'advapi32.dll:CryptDestroyKey'.
3. [SHAP: +0.241] Entrop√≠a global muy alta: mean(H) = 7.85 bits (umbral de alerta: 7.2).
4. [SHAP: +0.198] Subsistema declarado: WINDOWS_CUI. Sin imports de interfaz gr√°fica.
5. [SHAP: +0.155] Import detectado: 'user32.dll:GetAsyncKeyState' (captura de teclado).

=== METADATOS ADICIONALES ===
- TimeDateStamp: 2019-08-14 (consistente con muestra conocida de la familia Sodinokibi)
- Secci√≥n '.data': VirtualSize = 2,097,152 bytes / RawSize = 128 bytes (ratio 16,384x: posible packer)
- IoC encontrado en strings: "http://185.220.101.xx/payload" (IP asociada a C2 conocido)

Genera un reporte forense conciso (max 200 palabras) explicando el tipo de amenaza probable,
la cadena de ataque inferida y las recomendaciones de respuesta inmediata.
```

**Respuesta Esperada del LLM:**

> _"El an√°lisis converge fuertemente hacia un **Ransomware con capacidades de Keylogging secundario**, consistente con la familia **REvil/Sodinokibi**. La evidencia es multidimensional: (1) La combinaci√≥n de APIs criptogr√°ficas (`CryptEncrypt`) con acceso masivo al sistema de archivos (`FindFirstFile`) es la firma cl√°sica del proceso de cifrado de ransomware. (2) Los permisos RWX en `.text` y la enorme discrepancia VirtualSize/RawSize en `.data` apuntan a un packer custom que se descomprime en memoria en tiempo de ejecuci√≥n, evadiendo antivirus basados en firmas. (3) La importaci√≥n de `GetAsyncKeyState` sin interfaz gr√°fica sugiere un m√≥dulo secundario de captura de keystrokes, posiblemente para exfiltrar credenciales antes de cifrar. (4) La URL de C2 embebida confirma comunicaci√≥n activa con infraestructura de comando y control. **Recomendaci√≥n inmediata:** Aislar el endpoint de la red, preservar imagen forense de RAM, bloquear el IoC de red en el firewall perimetral y escalar al equipo de IR."_

---

## 10. Instalaci√≥n y Gu√≠a de Uso

### Requisitos Previos

| Requisito             | Versi√≥n M√≠nima                                | Notas                                                                       |
| :-------------------- | :-------------------------------------------- | :-------------------------------------------------------------------------- |
| **Sistema Operativo** | Linux Ubuntu 22.04+, Windows 10/11, macOS 12+ | Linux recomendado para producci√≥n. Windows soportado v√≠a PowerShell o WSL2. |
| **Python**            | 3.11.x                                        | Pol√≠tica oficial: `>=3.11,<3.12` para m√°xima reproducibilidad.              |
| **RAM**               | 4 GB m√≠nimo                                   | 8 GB recomendado para an√°lisis de lotes grandes.                            |
| **Disco**             | 500 MB libres                                 | Para el entorno virtual y los modelos.                                      |
| **Internet**          | Solo para instalaci√≥n                         | El an√°lisis funciona completamente offline.                                 |

### Instalaci√≥n Paso a Paso

**Paso 1 ‚Äî Clonar el repositorio:**

```bash
git clone https://github.com/IVAINX18/Shadownet_Defender_Extractor_V2.git
cd Shadownet_Defender
```

**Paso 2 ‚Äî Crear y activar el entorno virtual (Best Practice):**

```bash
# Crear el entorno virtual aislado (Python 3.11)
python3.11 -m venv .venv

# Activar en Linux/macOS (Bash/Zsh)
source .venv/bin/activate

# Activar en Windows (PowerShell)
# .venv\Scripts\Activate.ps1

# Activar en Windows (CMD)
# .venv\Scripts\activate.bat
```

> ‚ö†Ô∏è Siempre verifique que el entorno est√© activado antes de instalar dependencias (el prompt deber√≠a mostrar `(.venv)`).

**Paso 3 ‚Äî Instalar dependencias (lockfiles reproducibles):**

```bash
pip install --upgrade pip
pip install -r requirements.txt


**Paso 4 ‚Äî Verificar la instalaci√≥n:**

Ejecute el script de diagn√≥stico completo. Una instalaci√≥n exitosa mostrar√° logs con los tiempos de extracci√≥n y un score de probabilidad cercano a 0.0 (archivo benigno conocido):

```bash
python -m legacy.verify_refactor
```

La salida esperada incluye:

```
[INFO] Cargando modelo ONNX: models/best_model.onnx ... OK
[INFO] Cargando scaler: models/scaler.pkl ... OK
[INFO] Analizando: samples/procexp64.exe
[INFO] Extracci√≥n completada en 387ms | Vector dims: 2381
[INFO] Inferencia completada en 12ms
[RESULT] Score: 0.0023 | Veredicto: BENIGNO ‚úÖ
```

**Paso 5 ‚Äî Ejecutar la suite de tests:**

```bash
pytest tests/ -v
```

**Paso 6 ‚Äî Analizar un archivo propio:**

```bash
# An√°lisis de un archivo individual
python shadownet.py scan --file /ruta/al/archivo.exe

# An√°lisis de un directorio completo
python shadownet.py scan --directory /ruta/al/directorio/ --workers 4

# Exportar reporte en formato JSON
python shadownet.py scan --file /ruta/al/archivo.exe --output report.json
```

**Paso 7 ‚Äî Diagn√≥stico r√°pido de entorno:**

```bash
# 1) Verificar versi√≥n de Python (debe ser 3.11.x)
python --version

# 2) Verificar que el entorno virtual est√° activo
which python

# 3) Verificar integridad de dependencias instaladas
pip check

# 4) Smoke test de imports m√≠nimos del runtime
python -c "import pefile, numpy, scipy, sklearn, onnx, onnxruntime, joblib, rich, colorama, tqdm; print('runtime imports: OK')"
```

---

## 11. Conclusiones y Trabajo Futuro

ShadowNet Defender representa un hito significativo en nuestra formaci√≥n acad√©mica como investigadores de ciberseguridad. El proyecto demuestra de forma emp√≠rica y reproducible la viabilidad de aplicar t√©cnicas de _Big Data_ y _Deep Learning_ a uno de los problemas m√°s cr√≠ticos de la seguridad inform√°tica moderna: la detecci√≥n automatizada de malware a escala.

**Aprendizajes Principales Consolidados:**

1. **La Calidad del Dato es Suprema sobre los Algoritmos:** La transici√≥n de EMBER 2018 a SOREL-20M mejor√≥ las m√©tricas del modelo de forma m√°s significativa que cualquier ajuste de hiperpar√°metros o cambio arquitectural. Este es un aprendizaje fundamental para cualquier proyecto de ML aplicado: _garbage in, garbage out_.

2. **Feature Hashing como Soluci√≥n Elegante:** El _hashing trick_ para las tablas de imports es un ejemplo brillante de pragmatismo en Machine Learning: sacrifica un poco de precisi√≥n te√≥rica (colisiones) a cambio de escalabilidad pr√°ctica, y funciona extraordinariamente bien porque la redundancia del dataset compensa las colisiones.

3. **La Arquitectura Modular es una Inversi√≥n, no un Gasto:** Construir el sistema con Clean Architecture requiri√≥ m√°s tiempo inicial que un script monol√≠tico. Pero cada mejora posterior (nuevo bloque de features, cambio de dataset, integraci√≥n de ONNX) se implement√≥ en horas en lugar de d√≠as, sin romper el resto del sistema. La arquitectura modular pag√≥ su inversi√≥n inicial con creces.

4. **El An√°lisis Est√°tico tiene L√≠mites Conocidos:** Malware que se comporta de forma completamente leg√≠tima en disco (solo revelando su naturaleza en ejecuci√≥n) puede evadir el an√°lisis est√°tico. Esta limitaci√≥n motiva la Fase 3 del proyecto.

**Roadmap ‚Äî Pr√≥ximas Fases:**

| Fase                           | Objetivo                                                   | Tecnolog√≠a Propuesta                                                                                                           | Impacto Esperado                                                                 |
| :----------------------------- | :--------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------- |
| **Optimizaci√≥n del Extractor** | Reducir el tiempo de an√°lisis de ~400ms a < 50ms           | Reescritura del extractor en **Rust** con bindings Python (PyO3)                                                               | Permite an√°lisis en tiempo real de tr√°fico de red y copias masivas de archivos   |
| **An√°lisis Din√°mico Ligero**   | Complementar el an√°lisis est√°tico con evidencia conductual | Sandbox ligero basado en **Cuckoo** o instrumentaci√≥n con **frida**: ejecutar el malware 5 segundos y capturar syscalls reales | Detectar malware que se comporta de forma benigna en disco                       |
| **Integraci√≥n LLM (XAI)**      | Generar reportes forenses explicativos en lenguaje natural | LLM local (Llama-3-8B) + SHAP values + Prompt Engineering din√°mico                                                             | Reducir el tiempo de an√°lisis forense de un analista humano de horas a minutos   |
| **UI Gr√°fica (SOC Dashboard)** | Interfaz visual para centros de operaciones de seguridad   | Dashboard en Python (**Flet** o **Streamlit**) con visualizaciones de entrop√≠a, grafos de imports y timeline de escaneos       | Democratizar el acceso a la herramienta para equipos no t√©cnicos                 |
| **Integraci√≥n MISP/Cortex**    | Conectar con plataformas de inteligencia de amenazas       | API REST + plugins **MISP** y **TheHive/Cortex**                                                                               | Enriquecer autom√°ticamente los IoCs detectados con contexto de amenazas globales |

---

## 12. Referencias Bibliogr√°ficas

1. **Harang, R., & Rudd, E. M. (2020).** _SOREL-20M: A Large Scale Benchmark Dataset for Malicious PE Detection._ arXiv preprint arXiv:2012.07633. Sophos AI. [https://arxiv.org/abs/2012.07633](https://arxiv.org/abs/2012.07633)

2. **Anderson, H. S., & Roth, P. (2018).** _EMBER: An Open Dataset for Training Static PE Malware Machine Learning Models._ arXiv preprint arXiv:1804.04637. Endgame Inc. [https://arxiv.org/abs/1804.04637](https://arxiv.org/abs/1804.04637)

3. **Raff, E., Barker, J., Sylvester, J., Brim, R., Catanzaro, B., & Nicholas, C. K. (2017).** _Malware Detection by Eating a Whole EXE._ arXiv preprint arXiv:1710.09435. [https://arxiv.org/abs/1710.09435](https://arxiv.org/abs/1710.09435)

4. **Weinberger, K., Dasgupta, A., Langford, J., Smola, A., & Attenberg, J. (2009).** _Feature Hashing for Large Scale Multitask Learning._ Proceedings of the 26th Annual International Conference on Machine Learning (ICML). [https://dl.acm.org/doi/10.1145/1553374.1553516](https://dl.acm.org/doi/10.1145/1553374.1553516)

5. **Saxe, J., & Berlin, K. (2015).** _Deep Neural Network Based Malware Detection Using Two Dimensional Binary Program Features._ 10th International Conference on Malicious and Unwanted Software (MALWARE). IEEE. [https://ieeexplore.ieee.org/document/7413680](https://ieeexplore.ieee.org/document/7413680)

6. **Lundberg, S. M., & Lee, S.-I. (2017).** _A Unified Approach to Interpreting Model Predictions._ Advances in Neural Information Processing Systems (NeurIPS). [https://arxiv.org/abs/1705.07874](https://arxiv.org/abs/1705.07874)

7. **Martin, R. C. (2017).** _Clean Architecture: A Craftsman's Guide to Software Structure and Design._ Prentice Hall. ISBN: 978-0134494166.

8. **Ye, Y., Li, T., Adjeroh, D., & Iyengar, S. S. (2017).** _A Survey on Malware Detection Using Data Mining Techniques._ ACM Computing Surveys, 50(3), 1‚Äì40. [https://dl.acm.org/doi/10.1145/3073559](https://dl.acm.org/doi/10.1145/3073559)

---

<div align="center">

**Desarrollado con ‚ù§Ô∏è y ‚òï por el equipo de investigaci√≥n de INNOVASIC**

[INNOVASIC Research Lab](https://innovasicucc.wordpress.com/pagina/) ‚Äî Universidad Cooperativa de Colombia ‚Äî 2026

_Ivan Velasco (IVAINX_21) ¬∑ Santiago Cubillos (VANkLEis)_

</div>
