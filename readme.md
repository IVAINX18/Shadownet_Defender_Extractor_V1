# üõ°Ô∏è ShadowNet Defender (SND)

![License](https://img.shields.io/badge/license-MIT-blue) ![Python](https://img.shields.io/badge/python-3.10%2B-blue) ![Status](https://img.shields.io/badge/status-active-success) ![Dataset](https://img.shields.io/badge/dataset-SOREL--20M-orange) ![Model](https://img.shields.io/badge/model-LightGBM%2FONNX-green)

> **"Un sistema de defensa proactivo impulsado por Inteligencia Artificial y An√°lisis Est√°tico Avanzado."**

ShadowNet Defender es una soluci√≥n acad√©mica de ciberseguridad dise√±ada para cerrar la brecha entre el an√°lisis de malware tradicional y las t√©cnicas modernas de Deep Learning.

---

## üìñ √çndice Completo

1.  [Visi√≥n General](#-visi√≥n-general)
2.  [Arquitectura del Sistema](#-arquitectura-del-sistema)
3.  [Ingenier√≠a de Caracter√≠sticas en Profundidad](#-ingenier√≠a-de-caracter√≠sticas-en-profundidad)
    - [Fundamentos Matem√°ticos](#fundamentos-matem√°ticos)
    - [1. Byte Histogram (256 dims)](#1-byte-histogram-256-dims)
    - [2. Byte Entropy (256 dims)](#2-byte-entropy-256-dims)
    - [3. Strings & IoCs (104 dims)](#3-strings--ioc-metrics-104-dims)
    - [4. General & Header Info (72 dims)](#4-general--header-info-72-dims)
    - [5. Section Info (255 dims)](#5-section-info-255-dims)
    - [6. Imports & Exports Hashing (1408 dims)](#6-imports--exports-hashing-1408-dims)
4.  [Dataset SOREL-20M: An√°lisis](#-dataset-sorel-20m-an√°lisis)
5.  [Pipeline de Machine Learning](#-pipeline-de-machine-learning)
6.  [Estructura del Proyecto y M√≥dulos](#-estructura-del-proyecto-y-m√≥dulos)
7.  [Gu√≠a de Instalaci√≥n y Uso](#-gu√≠a-de-instalaci√≥n-y-uso)
8.  [Resultados, Benchmarks y Limitaciones](#-resultados-benchmarks-y-limitaciones)
9.  [Hoja de Ruta: IA Generativa y UI](#-hoja-de-ruta-ia-generativa-y-ui)
10. [Aspectos √âticos y Legales](#-aspectos-√©ticos-y-legales)
11. [Referencias Acad√©micas](#-referencias-acad√©micas)

---

## üëÅÔ∏è Visi√≥n General

**ShadowNet Defender (SND)** nace como respuesta a la creciente sofisticaci√≥n del malware moderno. Los atacantes utilizan t√©cnicas automatizadas de ofuscaci√≥n (polimorfismo, empaquetado personalizado) para generar miles de variantes √∫nicas de un mismo malware diariamente, haciendo ineficaces los antivirus basados en firmas est√°ticas (MD5/SHA256).

### üéØ El Problema: La Asimetr√≠a de la Ciberdefensa

Los defensores deben bloquear el 100% de los ataques, mientras que al atacante le basta con tener √©xito una sola vez. Los sistemas tradicionales fallan ante:

- **Malware Zero-Day**: Amenazas nunca antes vistas.
- **Ransomware Polim√≥rfico**: Variantes que cambian su hash en cada infecci√≥n.
- **Ataques "Living off the Land"**: Uso de herramientas leg√≠timas (PowerShell) con fines maliciosos.

### üí° La Soluci√≥n: Detecci√≥n Basada en Comportamiento Est√°tico

SND no ejecuta el archivo (evitando riesgos de infecci√≥n en el an√°lisis), sino que lo "radiograf√≠a". Utiliza un modelo de **Gradient Boosting (LightGBM)** entrenado con ~~20 millones~~ de muestras para aprender patrones abstractos de malicia.

El sistema detecta anomal√≠as sutiles:

- ¬øPor qu√© una calculadora necesita importar funciones de encriptaci√≥n?
- ¬øPor qu√© el 90% del archivo tiene una entrop√≠a m√°xima (encriptado)?
- ¬øPor qu√© no tiene interfaz gr√°fica pero importa funciones de teclado (keylogger)?

---

## üèóÔ∏è Arquitectura del Sistema

El proyecto sigue una estricta arquitectura por capas inspirada en principios de **Clean Architecture**, asegurando que la l√≥gica de extracci√≥n, el modelo y la interfaz est√©n desacoplados.

```mermaid
graph TD
    subgraph "Nivel 1: Entrada"
        A[Archivo PE Desconocido] -->|Stream de Bytes| B(Feature Extractor Engine);
    end

    subgraph "Nivel 2: Extracci√≥n (CPU Bound)"
        B --> C{Byte Analyzer};
        B --> D{PE Parser / pefile};
        C -->|Histogram & Entropy| E[Raw Features];
        D -->|Headers, Sections, Strings| E;
        D -->|Imports, Exports| F[Hasher Engine];
        F -->|Hashed Features| E;
    end

    subgraph "Nivel 3: Inferencia (AI Core)"
        E -->|Vector 2381-d| G[StandardScaler];
        G -->|Normalizaci√≥n (Array NumPy)| H[Modelo ONNX (LightGBM)];
        H -->|C√°lculo de Probabilidad| I(Score [0.0 - 1.0]);
    end

    subgraph "Nivel 4: Decisi√≥n y Reporte"
        I --> J{Umbral de Decisi√≥n};
        J -->|Score > 0.85| K[üî¥ MALWARE (High Confidence)];
        J -->|0.50 < Score <= 0.85| L[üü† MALWARE (Medium Confidence)];
        J -->|Score <= 0.50| M[üü¢ BENIGN];
    end
```

### Componentes Clave

1.  **Core Engine (`core/engine.py`)**: Orquestador principal. Carga modelos, gestiona errores y tiempos.
2.  **Extractors (`extractors/`)**: M√≥dulos independientes. Cada uno implementa la interfaz `FeatureBlock`. Si falla uno (e.g., cabecera corrupta), los dem√°s siguen funcionando.
3.  **ONNX Runner (`models/inference.py`)**: Abstracci√≥n sobre `onnxruntime`. Permite cambiar el modelo subyacente sin tocar el c√≥digo de la aplicaci√≥n.

---

## üß© Ingenier√≠a de Caracter√≠sticas en Profundidad

El extractor convierte un binario complejo en un vector de **2381 n√∫meros flotantes**. Este dise√±o es totalmente compatible con el est√°ndar **EMBER 2.0 / SOREL-20M**.

### Fundamentos Matem√°ticos

#### Normalizaci√≥n (Z-Score)

Los modelos de ML funcionan mejor cuando los datos tienen escalas similares. Aplicamos:
$$ z = \frac{x - \mu}{\sigma} $$
Donde $\mu$ es la media y $\sigma$ la desviaci√≥n est√°ndar calculada sobre el dataset de entrenamiento (SOREL-20M).

#### Feature Hashing (The Hashing Trick)

Para vectorizar datos categ√≥ricos de vocabulario abierto (nombres de librer√≠as), usamos hashing. Esto reduce la dimensionalidad y colisiones controladas.
$$ \phi(x) = \text{hash}(x) \pmod d $$
Donde $d$ es la dimensi√≥n del vector destino (1280 para imports).

---

### 1. Byte Histogram (256 dims)

Representa la frecuencia de aparici√≥n de cada byte posible (0-255).

- **F√≥rmula**: $H[i] = \frac{\text{count}(byte_i)}{\text{total\_bytes}}$
- **Utilidad**: Detecta ofuscaci√≥n. Los ejecutables normales tienen picos en bytes correspondientes a instrucciones comunes (`0x00` padding, `0xC3` ret). El malware encriptado tiende a una distribuci√≥n uniforme ("ruido blanco").

### 2. Byte Entropy (256 dims)

Calcula la **Entrop√≠a de Shannon** usando una ventana deslizante de 2048 bytes con un paso (stride) de 1024 bytes.
$$ H(X) = - \sum\_{i=0}^{255} p_i \log_2 p_i $$
El resultado es un histograma de entrop√≠as:

- **Eje X (Bins)**: Niveles de entrop√≠a (de 0.0 a 8.0 bits/byte).
- **Valor**: Proporci√≥n del archivo que tiene esa entrop√≠a.
- **Interpretaci√≥n**: Si la mayor√≠a del archivo tiene entrop√≠a ~8.0, est√° empaquetado o comprimido.

### 3. Strings & IoC Metrics (104 dims)

An√°lisis de cadenas extra√≠das con el comando `strings` (ASCII).

- **Estad√≠sticas**: Longitud promedio, n√∫mero de strings, entrop√≠a promedio.
- **Histogramas**: Distribuci√≥n de longitudes de strings.
- **IoC (Regex Match)**:
  - Rutas sospechosas (`C:\Temp`, `AppData`).
  - URLs (`http://`, `.onion`).
  - Registros (`HKEY_LOCAL_MACHINE`).
  - 'MZ' embebidos (indica otro ejecutable oculto dentro del archivo -> Dropper).

### 4. General & Header Info (72 dims)

Metadatos extra√≠dos directamente del `IMAGE_FILE_HEADER` y `IMAGE_OPTIONAL_HEADER`.

- **Timestamp**: Fecha de compilaci√≥n (√∫til, aunque falsificable).
- **Machine**: Arquitectura (x86, x64).
- **ImageBase**: Direcci√≥n de memoria preferida.
- **Subsystem**: GUI, Consola, Driver nativo. (Malware suele ser Consola o GUI invisible).

### 5. Section Info (255 dims)

An√°lisis profundo de secciones (`.text`, `.data`, `.rsrc`, etc.).

- **Nombres Hashed**: Se hace hash de los nombres de secci√≥n. Malware usa nombres no est√°ndar (e.g., `.upx0`, `.cryp`).
- **Propiedades**: Tama√±o virtual vs Tama√±o en disco.
- **Flags**: ¬øEs la secci√≥n ejecutable y escribible a la vez (`RWX`)? Esto es una **bandera roja** enorme, t√≠pica de malware auto-modificable o polim√≥rfico.

### 6. Imports & Exports Hashing (1408 dims)

Aqu√≠ reside gran parte del poder predictivo.

- **Imports (1280 dims)**: Funciones que el malware "pide" al sistema operativo.
  - _Ejemplo_: `kernel32.dll:WriteProcessMemory` (Inyecci√≥n de c√≥digo).
  - _Ejemplo_: `urlmon.dll:URLDownloadToFile` (Downloader).
- **Exports (128 dims)**: Funciones que el archivo ofrece (com√∫n en DLLs maliciosas o payloads de ataque lateral).

Se usa hashing **SHA-256** truncado y m√≥dulo N para mapear estas funciones al vector.

---

## üíæ Dataset SOREL-20M: An√°lisis

**SOREL-20M** es un hito en la investigaci√≥n de seguridad acad√©mica.

- **Tama√±o**: ~8 Terabytes de binarios (reducidos a features extra√≠dos).
- **Etiquetas**: Metadatos de detecci√≥n de m√∫ltiples motores comerciales (agregaci√≥n tipo VirusTotal).
- **Temporalidad**: Muestras recolectadas entre 2017 y 2019, permitiendo evaluar la capacidad de generalizaci√≥n temporal del modelo.

### ¬øPor qu√© no EMBER?

Aunque EMBER es excelente, SOREL es m√°s grande y su esquema de etiquetado es m√°s robusto para diferenciar entre _Adware_, _Ransomware_ y _Spyware_, lo que permitir√° en el futuro (Fase 2 del proyecto) clasificaci√≥n multiclase.

---

## üß† Pipeline de Machine Learning

### Modelo: LightGBM (Gradient Boosting Machine)

Elegido sobre redes neuronales profundas por:

1.  **Eficiencia en datos tabulares**: GBDT (Gradient Boosted Decision Trees) sigue siendo el estado del arte para vectores de caracter√≠sticas fijas.
2.  **Inferencia r√°pida**: Ideal para escaneo en tiempo real.
3.  **Interpretabilidad**: Permite calcular la "importancia de caracter√≠sticas" (Feature Importance), crucial para explicar por qu√© se detect√≥ un archivo.

### Exportaci√≥n a ONNX

El modelo se entrena en Python (scikit-learn/LightGBM) y se congela en ONNX.

- **Independencia**: No se necesita instalar `lightgbm` en el cliente final, solo `onnxruntime` (m√°s ligero).
- **Interoperabilidad**: El mismo archivo `.onnx` puede cargarse en una futura UI hecha en C#, Java o C++.

---

## üìÇ Estructura del Proyecto y M√≥dulos

Una explicaci√≥n detallada para desarrolladores o investigadores que deseen extender el proyecto.

```
shadownet/
‚îú‚îÄ‚îÄ configs/             # Configuraciones centralizadas (paths, umbrales)
‚îú‚îÄ‚îÄ core/                # L√≥gica de negocio
‚îÇ   ‚îú‚îÄ‚îÄ engine.py        # Clase ShadowNetEngine (Facade principal)
‚îÇ   ‚îî‚îÄ‚îÄ pipeline.py      # Definici√≥n de pasos de transformaci√≥n
‚îú‚îÄ‚îÄ extractors/          # L√≥gica de extracci√≥n (Extensible)
‚îÇ   ‚îú‚îÄ‚îÄ base.py          # Interfaz abstracta (FeatureBlock)
‚îÇ   ‚îú‚îÄ‚îÄ byte_hist.py     # Implementaci√≥n histograma
‚îÇ   ‚îú‚îÄ‚îÄ string_extractor.py # Implementaci√≥n strings
‚îÇ   ‚îî‚îÄ‚îÄ ...              # Resto de extractores
‚îú‚îÄ‚îÄ models/              # Gesti√≥n de modelos
‚îÇ   ‚îú‚îÄ‚îÄ inference.py     # ShadowNetModel (Manejo de ONNX Session)
‚îÇ   ‚îú‚îÄ‚îÄ model_loader.py  # Carga segura y validaci√≥n de hashes de modelos
‚îÇ   ‚îî‚îÄ‚îÄ scaler.pkl       # Objeto de normalizaci√≥n pre-entrenado
‚îú‚îÄ‚îÄ utils/               # Utilidades transversales
‚îÇ   ‚îú‚îÄ‚îÄ logger.py        # Logging profesional con 'rich'
‚îÇ   ‚îî‚îÄ‚îÄ file_ops.py      # Manejo seguro de archivos
‚îú‚îÄ‚îÄ samples/             # Archivos de prueba (e.g., procexp64.exe)
‚îú‚îÄ‚îÄ tests/               # Suite de tests autom√°ticos
‚îî‚îÄ‚îÄ legacy/              # C√≥digo archivado de versiones anteriores
```

---

## ‚öôÔ∏è Gu√≠a de Instalaci√≥n y Uso

### Entorno Recomendado

- **OS**: Linux (Ubuntu 22.04+)
- **Python**: 3.10+
- **RAM**: 4GB+ (para inferencia), 16GB+ (si se planea re-entrenar).

### Paso a Paso

1.  **Clonado y Entorno Virtual**:

    ```bash
    git clone https://github.com/IVAINX18/Shadownet_Defender.git
    cd Shadownet_Defender

    # Crear entorno virtual para aislar dependencias
    python3 -m venv .venv

    # Activar entorno
    source .venv/bin/activate
    ```

2.  **Instalaci√≥n de Dependencias**:
    Utilizamos versiones fijas (`==`) en `requirements.txt` para garantizar reproducibilidad.

    ```bash
    pip install -r requirements.txt
    ```

3.  **Verificaci√≥n de Integridad**:
    Ejecuta el script de diagn√≥stico para asegurar que el modelo y los extractores funcionan.

    ```bash
    python verify_refactor.py
    ```

4.  **Escaneo Personalizado**:
    Crea un script Python simple (`scan.py`):

    ```python
    from core.engine import ShadowNetEngine

    # Inicializar motor (carga modelo ONNX en memoria)
    engine = ShadowNetEngine()

    # Escanear ruta
    resultado = engine.scan_file("/ruta/a/archivo_sospechoso.exe")

    # Mostrar resultado JSON
    import json
    print(json.dumps(resultado, indent=4))
    ```

---

## üìä Resultados, Benchmarks y Limitaciones

### Rendimiento (Benchmark en i7-12700H)

| Operaci√≥n              | Tiempo Promedio | Notas                                      |
| :--------------------- | :-------------- | :----------------------------------------- |
| Carga de Modelo        | 150ms           | Solo ocurre una vez al inicio.             |
| Extracci√≥n de Features | 350-600ms       | Depende del tama√±o del archivo. I/O Bound. |
| Inferencia (ONNX)      | 15-30ms         | Extremadamente r√°pido. CPU Bound.          |
| **Total por archivo**  | **~0.5s**       | Apto para escaneo en tiempo real.          |

### Limitaciones Conocidas

1.  **Packers Ex√≥ticos**: Si un malware usa un packer comercial muy novedoso que comprime absolutamente todo (incluyendo headers), la extracci√≥n puede fallar o dar poca informaci√≥n.
2.  **Archivos .NET / Go**: El extractor actual est√° optimizado para binarios C/C++ (PE nativo). Binarios .NET pueden requerir features adicionales.
3.  **Adversarial Attacks**: Es te√≥ricamente posible modificar un malware (a√±adiendo secciones "buenas" o strings benignos) para enga√±ar al modelo.

---

## üîÆ Hoja de Ruta: IA Generativa y UI

### Fase 2: Integraci√≥n LLM (Q3 2026)

El objetivo es pasar de una "Caja Negra" (Score 0.99) a una "Caja de Cristal".
Integraremos un modelo **LLM Peque√±o (SLM)** como _TinyLlama_ o _Phi-3_ localmente.

**Flujo propuesto**:

1.  ShadowNet detecta malware.
2.  Se identifican los features que m√°s contribuyeron a la decisi√≥n (usando SHAP values).
    - _Ej: Importa `SetWindowsHookEx`, Secci√≥n `.text` escribible._
3.  Se construye un prompt para el LLM:
    - _"Analiza estos indicadores t√©cnicos y explica a un usuario no experto qu√© riesgo suponen."_
4.  El LLM genera un reporte ejecutivo.

### Fase 3: Interfaz Gr√°fica (UI)

Desarrollo de una aplicaci√≥n de escritorio moderna.

- **Tecnolog√≠a**: Custom Tkinter o Flet (Python) para mantener el stack unificado.
- **Funciones**: Drag & Drop, historial de escaneos, visualizaci√≥n gr√°fica de entrop√≠a.

---

## ‚öñÔ∏è Aspectos √âticos y Legales

Este software ha sido desarrollado con fines **estrictamente acad√©micos y defensivos**.

- **No contiene malware**: El repositorio no distribuye muestras maliciosas. Los tests usan archivos benignos o "dummy files".
- **Uso Responsable**: El autor no se hace responsable del uso de esta herramienta en entornos cr√≠ticos sin la debida validaci√≥n adicional.
- **Privacidad**: Todo el an√°lisis es **local**. Ning√∫n archivo sale del equipo del usuario hacia la nube.

---

## üìö Referencias Acad√©micas

Para profundizar en la ciencia detr√°s de ShadowNet:

1.  **SOREL-20M Paper**: Harang, R., & Rudd, E. M. (2020). _SOREL-20M: A Large Scale Benchmark Dataset for Malicious PE Detection_. arXiv:2012.07633.
2.  **Dataset EMBER**: Anderson, H. S., & Roth, P. (2018). _EMBER: An Open Dataset for Training Static PE Malware Machine Learning Models_. arXiv:1804.04637.
3.  **Feature Hashing**: K. Weinberger, et al. (2009). _Feature Hashing for Large Scale Multitask Learning_. ICML.
4.  **Adversarial ML**: Goodman, D., et al. (2020). _AdvBox: A Toolbox to Generate Adversarial Examples that Fool Neural Networks_.

---

### üë®‚Äçüíª Autor y Contacto

**Desarrollado por:** IVAINX y VANkLEis
**Rol:** Estudiantes de Ingenier√≠a en Sistemas & Investigadores de INNOVASIC
**A√±o:** 2026
**Licencia:** ShadowNet License

---

_Hecho con ‚ù§Ô∏è y ‚òï para hacer de Internet un lugar m√°s seguro._
